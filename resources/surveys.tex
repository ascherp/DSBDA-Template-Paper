\section{Surveys}

\subsection{General Machine Learning}

\paragraph{Attention}

\begin{itemize}
\item A General Survey on Attention Mechanisms in Deep Learning, https://arxiv.org/abs/2203.14263

\item \New Disentangled Representation Learning, \url{https://ieeexplore.ieee.org/document/10579040}
\end{itemize}

\paragraph{Continual Learning}

\begin{itemize}
\item A Wholistic View of Continual Learning with Deep Neural Networks: Forgotten Lessons and the Bridge to Active and Open World Learning, https://arxiv.org/abs/2009.01797

\item A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning, https://www.sciencedirect.com/science/article/pii/S089360802300014X
\end{itemize}

\paragraph{Distillation}

\begin{itemize}
\item Knowledge Distillation: A Survey, https://arxiv.org/abs/2006.05525
\end{itemize}

\subsection{Graph Representation Learning}

\begin{itemize}
\item Architectures of Topological Deep Learning: A Survey of Message-Passing Topological Neural Networks, \url{https://arxiv.org/abs/2304.10031}

\item Foundations and Frontiers of Graph Learning Theory, \url{https://arxiv.org/abs/2407.03125}

\item Deep Learning on Graphs: A Survey,
\url{https://arxiv.org/abs/1812.04202}

\item Comprehensible Artificial Intelligence on Knowledge Graphs: A survey, \url{https://www.sciencedirect.com/science/article/pii/S1570826823000355}
  
\item A review of graph neural networks: concepts, architectures, techniques, challenges, datasets, applications, and future directions, \url{https://journalofbigdata.springeropen.com/articles/10.1186/s40537-023-00876-4}

\item A survey of graph neural networks in various learning paradigms: methods, applications, and challenges, \url{https://link.springer.com/article/10.1007/s10462-022-10321-2}

\item A Comprehensive Survey on Automatic Knowledge Graph Construction, \url{https://dl.acm.org/doi/10.1145/3618295}

\item A Comprehensive Survey on Deep Graph Representation Learning Methods, \url{https://dl.acm.org/doi/pdf/10.1613/jair.1.14768}

\item Graph Self-Supervised Learning: A Survey, \url{https://arxiv.org/abs/2103.00111}

\item Position Paper: Challenges and Opportunities in Topological Deep Learning, \url{https://arxiv.org/abs/2402.08871}

\item Uncertainty in Graph Neural Networks: A Survey, \url{https://arxiv.org/abs/2403.07185}

\item Attending to Graph Transformers, \url{https://arxiv.org/abs/2302.04181}
\end{itemize}

\paragraph{Temporal Graphs}

\begin{itemize}
\item Signal Processing over Time-Varying Graphs: A Systematic Review, https://arxiv.org/abs/2412.00462

\item A Survey on Temporal Knowledge Graph Completion: Taxonomy, Progress, and Prospects, https://arxiv.org/abs/2308.02457

\item A Comprehensive Survey of Dynamic Graph Neural Networks: Models, Frameworks, Benchmarks, Experiments and Challenges,
\url{https://arxiv.org/abs/2405.00476}
\end{itemize}
 

\paragraph{Graphs meet LLMs}

\begin{itemize}
\item A Survey of Large Language Models for Graphs, \url{https://arxiv.org/abs/2405.08011}
\end{itemize}

\paragraph{Graphs meet LLMs}

\begin{itemize}
\item \New Graph Neural Networks for Databases: A Survey, \url{https://arxiv.org/abs/2502.12908}
\end{itemize}

\paragraph{Continual Graph Learning}

\begin{itemize}
\item Continual Graph Learning: A Survey, https://arxiv.org/abs/2301.12230
\end{itemize}
  

\paragraph{Graphs and Heterophily}

\begin{itemize}
\item The Heterophilic Graph Learning Handbook: Benchmarks, Models, Theoretical Analysis, Applications and Challenges, \url{https://arxiv.org/abs/2407.09618}
\end{itemize}


\paragraph{Summarization of Graphs}

\begin{itemize}
\item A Survey on Graph Condensation, https://arxiv.org/abs/2402.02000

\item A Comprehensive Survey on Graph Summarization with Graph Neural Networks, https://arxiv.org/abs/2302.06114

\item A Survey on Extractive Knowledge Graph Summarization: Applications, Approaches, Evaluation, and Future Directions, https://arxiv.org/abs/2402.12001

\item A Comprehensive Survey on Graph Reduction: Sparsification, Coarsening, and Condensation, https://arxiv.org/abs/2402.03358

\item A Survey on Structure-Preserving Graph Transformers, https://arxiv.org/abs/2401.16176
\end{itemize}


\paragraph{Structural Graph Summarization}

\begin{itemize}
\item Structural Summarization of Semantic Graphs Using Quotients, https://doi.org/10.4230/TGDK.1.1.12
\end{itemize}
 
\paragraph{Link Prediction}

\begin{itemize}
\item Beyond Transduction: A Survey on Inductive, Few Shot, and Zero Shot Link Prediction in Knowledge Graphs, https://arxiv.org/abs/2312.04997

\item A Survey on Graph Classification and Link Prediction based on GNN, https://arxiv.org/abs/2307.00865
\end{itemize}

\paragraph{Recommender}

\begin{itemize}
\item A survey of graph neural network based recommendation in social networks, https://www.sciencedirect.com/science/article/abs/pii/S0925231223005647

\item Graph Neural Networks in Recommender Systems: A Survey, https://arxiv.org/abs/2011.02260

\item A Survey of Graph Neural Networks for Recommender Systems: Challenges, Methods, and Directions, https://dl.acm.org/doi/full/10.1145/3568022
\end{itemize}

\paragraph{Distillation}

\begin{itemize}
\item Graph-based Knowledge Distillation: A survey and experimental evaluation, https://arxiv.org/abs/2302.14643

\item Knowledge Distillation on Graphs: A Survey, https://arxiv.org/abs/2302.00219
\end{itemize}

\paragraph{Continual Learning}

\begin{itemize}
\item Continual Learning on Graphs: Challenges, Solutions, and Opportunities, https://arxiv.org/abs/2402.11565

\item Graph Learning under Distribution Shifts: A Comprehensive Survey on Domain Adaptation, Out-of-distribution, and Continual Learning, https://arxiv.org/abs/2402.16374
\end{itemize}

\paragraph{Knowledge Graphs meet LLMs}

\begin{itemize}
\item Combining Knowledge Graphs and Large Language Models, \url{https://arxiv.org/abs/2407.06564}

TL;DR: An analysis of 28 papers outlining methods for KG-powered LLMs, LLM-based KGs, and LLM-KG hybrid approaches
\end{itemize}

\paragraph{Graphs and OOD}

\begin{itemize}
\item Out-of-Distribution Detection on Graphs: A Survey,
\url{https://arxiv.org/abs/2502.08105}
\end{itemize}


\subsection{Foundation Models}

\begin{itemize}
\item \New (Mis)Fitting: A Survey of Scaling Laws, \url{https://arxiv.org/abs/2502.18969}
\end{itemize}

\subsection{Natural Language Processing / LLMs}

\begin{itemize}
\item On the Opportunities and Risks of Foundation Models, https://arxiv.org/abs/2108.07258 [argue among others that due to the huge resources required by language models, research on them is pushed into the hands of a few global industrial players only]


\item \New A Survey of Multi-task Learning in Natural Language Processing: Regarding Task Relatedness and Training Methods, \url{https://aclanthology.org/2023.eacl-main.66/}

\item \New Open Problems in Mechanistic Interpretability, \url{https://arxiv.org/abs/2501.16496}

\item \New A Survey on Mechanistic Interpretability for Multi-Modal Foundation Models, \url{https://arxiv.org/abs/2502.17516}
\end{itemize}

\paragraph{LLM}

* A Survey of Mamba, https://arxiv.org/abs/2408.01129

* A Comprehensive Overview of Large Language Models, https://arxiv.org/abs/2307.06435

* Large Language Models: A Survey, https://arxiv.org/abs/2402.06196

* The Life Cycle of Knowledge in Big Language Models: A Survey, https://arxiv.org/abs/2303.07616

* A Survey of Large Language Models, https://arxiv.org/abs/2303.18223

* A Survey of Knowledge Enhanced Pre-Trained Language Models, https://ieeexplore.ieee.org/document/10234662

* A Survey on Deep Semi-Supervised Learning, https://ieeexplore.ieee.org/document/9941371

* The Prompt Report: A Systematic Survey of Prompting Techniques, https://arxiv.org/abs/2406.06608

\paragraph{Prompting LLM}

* The Prompt Report: A Systematic Survey of Prompting Techniques, \url{https://arxiv.org/abs/2406.06608}

\paragraph{Efficient LLM}

* Efficient Large Language Models: A Survey, https://arxiv.org/abs/2312.03863 and https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey

\paragraph{Personalized LLMs}

* Personalization of Large Language Models: A Survey, \url{https://arxiv.org/abs/2411.00027}

\paragraph{Continual LLM}

* Continual Learning for Large Language Models: A Survey, https://arxiv.org/abs/2402.01364

\paragraph{Classification}

* A Survey of Text Classification With Transformers: How Wide? How Large? How Long? How Accurate? How Expensive? How Safe?, https://ieeexplore.ieee.org/document/10380590

* Graph Neural Networks for Text Classification: A Survey, https://arxiv.org/abs/2304.11534

* Recent Advances in Hierarchical Multi-label Text Classification: A Survey, https://arxiv.org/abs/2307.16265

* Text classification using embeddings: a survey, https://link.springer.com/article/10.1007/s10115-023-01856-z

* Deep learning, graph-based text representation and classification: a survey, perspectives and challenges, https://link.springer.com/article/10.1007/s10462-022-10265-7

* A Survey of Cross-Lingual Text Classification and Its Applications on Fake News Detection, https://www.worldscientific.com/doi/10.1142/S2811032323500030

\paragraph{Augmentation}

* A Survey on Data Augmentation for Text Classification, https://dl.acm.org/doi/10.1145/3544558

* Augmented Language Models: a Survey, https://arxiv.org/abs/2302.07842

* Retrieval-Augmented Generation for Large Language Models: A Survey, https://arxiv.org/abs/2312.10997
 
\paragraph{KG Editing with LLM}

* Knowledge Editing for Large Language Models: A Survey, https://arxiv.org/abs/2310.16218

\paragraph{Graphs for NLP}

* Graph Neural Networks for Natural Language Processing, \url{https://arxiv.org/abs/2106.06090}

\paragraph{Interpretability}

* Post-hoc Interpretability for Neural NLP: A Survey, https://arxiv.org/abs/2108.04840
 
\paragraph{Specific Domains}

* Artificial Intelligence for Literature Reviews: Opportunities and Challenges, https://arxiv.org/abs/2402.08565
 
\paragraph{Instance Selection}

* A Comparative Survey of Instance Selection Methods applied to Non-Neural and Transformer-Based Text Classification, https://dl.acm.org/doi/10.1145/3582000 

\paragraph{Question Answering}

* Deep learning-based question answering: a survey, https://link.springer.com/article/10.1007/s10115-022-01783-5

* Modern Question Answering Datasets and Benchmarks: A Survey, https://arxiv.org/abs/2206.15030

LLMs and code

* Large Language Models for Code Completion: A Systematic Literature Review, 
\url{https://www.sciencedirect.com/science/article/pii/S0920548924000862}
 
\subsection{Information Retrieval}

* A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models, \url{https://arxiv.org/abs/2405.06211}

* A Survey of Generative Search and Recommendation in the Era of Large Language Models,
https://arxiv.org/abs/2404.16924

* Large Language Models for Information Retrieval: A Survey, https://arxiv.org/abs/2308.07107

* Neural Approaches to Conversational Information Retrieval, https://arxiv.org/pdf/2201.05176.pdf

\paragraph{Ranking}

* Pretrained Transformers for Text Ranking: BERT and Beyond, https://arxiv.org/abs/2010.06467

* Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges, https://dl.acm.org/doi/10.1145/3648471

* Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting, https://arxiv.org/abs/2306.17563

Code Search

* Survey of Code Search Based on Deep Learning, \url{https://arxiv.org/abs/2305.05959}

\subsection{Time Series Analysis}

\begin{itemize}
\item Foundation Models for Time Series Analysis: A Tutorial and Survey, \url{https://arxiv.org/abs/2403.14735}
\end{itemize}
